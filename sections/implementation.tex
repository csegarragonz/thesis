\chapter{Implementation} \label{chap:implementation}
% TODO: include code listings in this section!!
% TODO: Add appendix with all docker deployment files.

The aim of this chapter is to present the implementation details of \projName.
Each explanation is accompanied, when required, by code snippets to further illustrate the rationale behind our design choices.
For the full implementation details we refer to Appendix \ref{chap:app-code}.
The implementation we will cover is the one the results presented in Chapter \ref{chap:evaluation} are based on.
As a consequence, and in order to stress-test \projName, we replace real sensors with synthetic data generators in the client package first described in \S\ref{sec:clients}.
All the different components introduced in Chapter \ref{chap:architecture} are packaged in sets of Docker containers.
Large fleets of concurrent users are then simulated using Docker's standalone clusters and mounted using \texttt{docker-machine}.

The rest of the Chapter is structured as follows.
In \S\ref{sec:server-implementation} and \S\ref{sec:client-implementation} we cover the implementation details of the server-side and the client-side component respectively.
Re-using Docker-speciphic nomenclature, we will refer to logical isolated functionalities packaged in a container as \emph{services}.
Sets of services working collaboratively will be gathered and deployed as a \emph{component} using \texttt{docker-compose}.
Collections (or clusters) of replicated components form \emph{swarms} using \texttt{docker-swarm}.
Lastly, in \S\ref{sec:deployment} we cover how each service, component and swarm is deployed.
Furthermore, even if only snippets of code are included in this Chapter, the full source code is available in Appendix \ref{chap:app-code}.

\section{Server Implementation} \label{sec:server-implementation}

We rely on the original \sgxspark implementation, and we only modify it to support a different in-enclave code deployment path, so that the \texttt{.jar} archive is available inside the enclaves and the shared memory. 
To do so, we include our newly added module in the project's \texttt{pom.xml} compilation file, in the worker and driver initialization scripts and in the enclave generation \texttt{Makefile} so that code is loaded in the enclave at compilation time.
The before-mentioned module contains a two HRV processing algorithms and a benchmarking one: \texttt{SDNN}, \texttt{HRVBands}, and \texttt{Identity}.
The \texttt{SDNN} algorithm computes the standard deviation of NN (RR) intervals in a rolling basis, generating one output per 10 seconds worth of samples.
The \texttt{HRVBands}~\cite{Shaffer2017} performs a Discrete Fourier Transform (DFT) of 10 seconds worth of samples, and computes the power of the low frequency and high frequency compoents, together with their ratio.
Lastly, the \texttt{Identity} algorithm copies the input to the output file.
It is used to provide a baseline on the overhead the system is introducing.
All the application code is implemented in \textsc{Spark}'s binding for the \textsc{Scala} programming language~\cite{scala-language}. 
We choose this particular binding since it is the only one supported by \sgxspark's compiler.
To be usable inside \sgx enclaves, applications must adhere to the RDD~\cite{rdd-programming-guide} and DStreams~\cite{ZahariaDStreams2012} API.

The particular implementation of these algorithms relies on basic Spark Streaming operators, and their corresponding Scala counterparts.
For instance, the fylesystem interface is monitored using DStream's \texttt{textFileStream} method as exposed in Listing~\ref{code:text-file-stream}.
\begin{lstlisting}[language=Scala,caption={Snippet illustrating \texttt{textFileStream} functionality.},label=code:text-file-stream]
 object HelloWorld {
    def main(args: Array[String]) {
      println("Hello, world!")
      yield
    }
  }
\end{lstlisting}
Lastly, the implementations of \texttt{SDNN}, \texttt{HRVBands}, and \texttt{Identity} can be found in Listings~\ref{code:sdnn},~\ref{code:hrvbands}, and~\ref{code:identity} respectively.

\section{Client Implementation} \label{sec:client-implementation}

Clients correspond to body-sensors strapped to the body of a user. 
In a real deployment, the sensor service in the client component would be an actual sensor strapped to the user's body (\textit{e.g.} HR band, smartwatch, optical HR monitoring device, ...) and the gateway would be implemented in a, for instance, \textsc{Raspberry Pi}.
For evaluation purposes (see Chapter~\ref{chap:evaluation}), these services are simulated and virtualized.
This way we can simulate a situation where multiple clients concurrently use \projName without the hardware burden.
As firstly introduced in \S\ref{sec:clients}, our implementation decouples the client component into into five different services (see Figure~\ref{fig:system-architecture}, right). 
\begin{enumerate}
    \item The \texttt{sensor} service is a \textsc{Python} script that generates \texttt{sample\_rate} random samples per second, generates the corresponding timestamps, and publishes the information to the \texttt{artificial-data} topic in a \textsc{MQTT}~\cite{mqtt-protocol} broker located in the gateway. Listing~\ref{code:sensor-data-gen} presents the part of the \texttt{sensor} source code where artifical data is generated and published. The full source code is available in Listing~\ref{code:sensor}.
\begin{lstlisting}[language=Python,caption={Snippet illustrating the artificial data generation in the \texttt{sensor} service.},label=code:sensor-data-gen]
 object HelloWorld {
    def main(args: Array[String]) {
      println("Hello, world!")
      yield
    }
  }
\end{lstlisting}
    \item The \texttt{eclipse-mqtt} service is the \texttt{mosquitto}~\cite{mqtt-eclipse} implementation of the \textsc{MQTT} broker. We rely on the public Docker image at Docker Hub~\cite{mqtt-image}. It handles the samples generated by \texttt{sensor} and delivers them to the \texttt{mqtt-subscriber} when the latter subscribes to the \texttt{artificial-data} topic.
    \item The \texttt{mqtt-subscriber} service is a \textsc{Python} script that subscribes to the \texttt{artificial-data} \textsc{MQTT} topic and whenever it gathers \texttt{FILE\_LINES} samples it generates a \texttt{.csv} file at a specified location. The key functionality of the service, sample gathering and file generation, is illustrated in Listing~\ref{cite:mqtt-sub-short}. The full service code is available in Listing~\ref{code:mqtt-sub}.
\begin{lstlisting}[language=Python,caption={Snippet illustrating the data gathering and file generation in the \texttt{mqtt-subscriber} service.},label=code:mqtt-sub-short]
 object HelloWorld {
    def main(args: Array[String]) {
      println("Hello, world!")
      yield
    }
  }
\end{lstlisting}
\end{enumerate}
For evaluation purposes, the \texttt{sensor} is a \textsc{Python} service that generates random RR intervals.
These are published into the \textsc{MQTT} queue~\cite{mqtt-protocol,mqtt-eclipse} following a uniform time distribution. 
The gateway is composed by a \textsc{MQTT} queue and broker service.
We rely on \texttt{eclipse-mosquitto}\footnote{\url{https://hub.docker.com/_/eclipse- mosquitto/}}, a \texttt{mqtt-sub} service that subscribes to the specific topic and generates data files with several samples, and a \texttt{producer} and \texttt{consumer} services that interact with the remote filesystem.
These components are implemented in Python, and consist of $888$ LoC. %~\cs{Here I do not account for the mqtt image which I do not know what is implemented in}
% (being the last three implemented in \textsc{Python}). 
Our prototype relies on Docker to facilitate the deployment of new clients, and on \texttt{docker-compose}~\cite{docker-compose} to easily group orchestrate their deployment. % along the mentioned micro-services.
%A single client can be deployed in isolation using \texttt{docker-compose}, running a total of five different services (with their corresponding image and \texttt{Dockerfile}). 
The communication between the client and the server happens via SSH/SecureFTP to ensure transport layer security when transfering user's data. %\vs{TO DO what? Complete..}.

\section{Deployment} \label{sec:deployment}

